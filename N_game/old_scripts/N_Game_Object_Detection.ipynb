{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from random import shuffle\n",
    "import urllib.request\n",
    "import imutils\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,TensorBoard,TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\Users\\Jordan\\Desktop\\N_game_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_raw_images():\n",
    "    #'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n12830222'\n",
    "    neg_images_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03743016'\n",
    "    neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
    "    pic_num = 1\n",
    "    \n",
    "    img_path = r\"C:\\Users\\Jordan\\Desktop\\N_game_images\"\n",
    "    \n",
    "    for i in neg_image_urls.split('\\n'):\n",
    "        try:\n",
    "            print(i)\n",
    "            urllib.request.urlretrieve(i, img_path+'\\\\negatives\\\\negatives'+str(pic_num)+'.jpg')\n",
    "            img = cv2.imread(img_path+'\\\\negatives\\\\negatives'+str(pic_num)+'.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "            # should be larger than samples / pos pic (so we can place our image on it)\n",
    "            resized_image = cv2.resize(img, (100, 100))\n",
    "            cv2.imwrite(img_path+'\\\\negatives\\\\negatives'+str(pic_num)+'.jpg',resized_image)\n",
    "            pic_num += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_type in [img_path]:\n",
    "    for img in os.listdir(file_type+'\\\\originals'):\n",
    "        positive = cv2.imread(img_path+'\\\\originals\\\\'+str(img))\n",
    "        resize_positive = cv2.resize(positive,(50,50))\n",
    "        cv2.imwrite(img_path+'\\\\positives\\\\'+str(img),resize_positive)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_type in [img_path]:\n",
    "    for img in os.listdir(file_type+'\\\\positives'):\n",
    "        positive = cv2.imread(img_path+'\\\\positives\\\\'+str(img))\n",
    "        for angle in np.arange(5,360,5):\n",
    "            rotated = imutils.rotate_bound(positive, angle)\n",
    "            cv2.imwrite(img_path+'\\\\positives\\\\'+str(img)[:-4]+'_'+str(angle)+'.JPG',rotated)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Users\\Jordan\\Desktop\\N_game_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "for file_type in tqdm([img_path]):\n",
    "    for img in os.listdir(file_type+'\\\\originals'):\n",
    "        positive = cv2.imread(img_path+'\\\\originals\\\\'+str(img))\n",
    "        for angle in np.arange(5,360,10):\n",
    "            rotated = imutils.rotate_bound(positive, angle)\n",
    "            cv2.imwrite(img_path+'\\\\originals_rotated\\\\'+str(img)[:-4]+'_'+str(angle)+'.JPG',rotated)\n",
    "            for s in np.arange(20,600,20):\n",
    "                gaus = cv2.randn(rotated,mean,int(s))\n",
    "                cv2.imwrite(img_path+'\\\\originals_rotated\\\\'+str(img)[:-4]+'_'+str(angle)+'_gauss_sd_'+str(s)+'.JPG',gaus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = img_path + \"\\\\originals_rotated\"\n",
    "test_dir = img_path + \"\\\\originals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_labels(images_path):\n",
    "    original_labels_list = []\n",
    "    for file_type in [img_path]:\n",
    "        for img in os.listdir(file_type+'\\\\originals'):\n",
    "            original_labels_list.append(img.split('.')[0])\n",
    "            \n",
    "        return original_labels_list\n",
    "\n",
    "\"\"\"Convolution Neural Networks require a binary array the \n",
    "length of the number of images needed to be classified\n",
    "as a label, with 1 corresponding to image of interest\"\"\"\n",
    "def label_img(image,labels_list):\n",
    "    \n",
    "    #merge repeated labels\n",
    "    new_labels = labels_list\n",
    "    for i,label in enumerate(labels_list):\n",
    "        new_labels[i] = re.sub('[0-9]+', '',label) #remove number from label\n",
    "    new_labels = list(set(new_labels))\n",
    "    new_labels.sort()\n",
    "\n",
    "    for output,label in enumerate(new_labels):\n",
    "        word_label = image.split('.')[0]\n",
    "        \n",
    "        if label in word_label:\n",
    "            label_array= keras.utils.to_categorical(output,num_classes=len(new_labels)) #populates image position with 1\n",
    "            return label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= original_labels(test_dir)\n",
    "\n",
    "merged_labels = labels\n",
    "for i,label in enumerate(labels):\n",
    "     merged_labels[i] = re.sub('[0-9]+', '',label) #remove number from label\n",
    "merged_labels = list(set(merged_labels))\n",
    "merged_labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for img in tqdm(os.listdir(train_dir)):\n",
    "        label = label_img(img,labels)\n",
    "        path = os.path.join(train_dir,img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (img_size,img_size))\n",
    "        img = img.reshape([img_size,img_size,1])\n",
    "        training_data.append(img)\n",
    "        training_labels.append(label) #use for sentdex tutorial\n",
    "    \n",
    "    training_data,training_labels= sk.utils.shuffle(training_data,training_labels)\n",
    "    training_data = np.array(training_data)\n",
    "    \n",
    "    #training_data = training_data.reshape(training_data.shape[0],img_size,img_size,1)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    np.save('train_labels.npy',training_labels)\n",
    "    return training_data,training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data,training_labels = create_train_data()\n",
    "training_data = np.load('C:\\\\Users\\\\Jordan\\\\Desktop\\\\N_game_images\\\\train_data.npy',allow_pickle=True,encoding='latin1')\n",
    "training_labels = np.load('C:\\\\Users\\\\Jordan\\\\Desktop\\\\N_game_images\\\\train_labels.npy',allow_pickle=True,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    testing_labels = []\n",
    "    for img in tqdm(os.listdir(test_dir)):\n",
    "        label = label_img(img,labels)\n",
    "        path = os.path.join(test_dir,img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)       \n",
    "        img = cv2.resize(img,(img_size,img_size))\n",
    "        img = img.reshape([img_size,img_size,1])\n",
    "        testing_data.append(img) #use for sentdex tutorial\n",
    "        testing_labels.append(label)\n",
    "        \n",
    "        \n",
    "    #testing_data,testing_labels= sk.utils.shuffle(testing_data,testing_labels)\n",
    "    testing_data = np.array(testing_data)\n",
    "    \n",
    "    \n",
    "    np.save('test_data.npy', testing_data)\n",
    "    np.save('test_labels.npy',testing_labels)\n",
    "    return testing_data,testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_data,testing_labels = process_test_data()\n",
    "testing_data = np.load('test_data.npy',allow_pickle=True,encoding='latin1')\n",
    "testing_labels = np.load('test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_node_num = 64\n",
    "learning_rate = 1e-3\n",
    "full_node = [4096] #4096 working best\n",
    "\n",
    "for node in full_node:\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    model_name = 'n_game_objects-{}-{}-64-{}.h5'.format(learning_rate, '6conv-basic',node)\n",
    "\n",
    "    if os.path.exists('{}.meta'.format(model_name)):\n",
    "        keras.models.load_model(model_name)\n",
    "        print('model loaded!')\n",
    "    else:\n",
    "        convnet = tflearn.input_data(shape=[None, img_size, img_size, 1], name='input')\n",
    "\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "        \n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "        convnet = fully_connected(convnet, node, activation='relu')\n",
    "        convnet = dropout(convnet, 0.8)\n",
    "\n",
    "        convnet = fully_connected(convnet, 30, activation='softmax') #output layer, second number corresponds to number of outputs\n",
    "        convnet = regression(convnet, optimizer='adam', \n",
    "                             learning_rate=learning_rate, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "        model = tflearn.DNN(convnet, tensorboard_dir = 'log')\n",
    "\n",
    "\n",
    "        train = training_data[:-500]\n",
    "\n",
    "        test = training_data[-500:]\n",
    "\n",
    "        X = np.array([i[0] for i in train]).reshape(-1,img_size,img_size,1)\n",
    "        Y = [i[1] for i in train]\n",
    "\n",
    "        test_x = np.array([i[0] for i in test]).reshape(-1,img_size,img_size,1)\n",
    "        test_y = [i[1] for i in test]\n",
    "        \n",
    "        print(model_name)\n",
    "\n",
    "        model.fit({'input': X}, {'targets': Y}, n_epoch=1, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "        snapshot_step=500, show_metric=True, run_id=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#keras.models.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=log/ --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[keras.callbacks.TensorBoard(log_dir=\"log\\\\{}\".format(model_name), \n",
    "                                                     histogram_freq=1, write_graph=True, write_images=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tutorial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training and testing data\n",
    "training_data = training_data.astype('float32')\n",
    "testing_data = testing_data.astype('float32')\n",
    "training_dataNorm = training_data/255\n",
    "testing_dataNorm = testing_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "for i in range(testing_data.shape[0]):\n",
    "    plt.subplot(6,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(merged_labels[np.argmax(testing_labels[i])])\n",
    "    plt.imshow(np.squeeze(testing_data[i]), cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a convolution neural network model\n",
    "def create_CNN(input_data,cnn_nodes = 32, full_nodes = 512, output_nodes = 30,\n",
    "                 hidden_layers = 6,fully_connected = 1,reg=0.0005,learn_rate=1e-4):\n",
    "    \n",
    "    #have to always clear keras session whenever running a new model\n",
    "    keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    \n",
    "    reg = keras.regularizers.l2(reg)\n",
    "    \n",
    "    #check dimensions of input data, must correspond to that of one image (3D)\n",
    "    if np.ndim(input_data) > 3:\n",
    "        input_data = input_data[1] #removes four dimension\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    #input layer\n",
    "    model.add(Conv2D(cnn_nodes, (3, 3), kernel_regularizer = reg,\n",
    "                     input_shape=([60,60,1])))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    multiplier = 2\n",
    "    for iLayers in range(hidden_layers):\n",
    "        #hidden layers\n",
    "        model.add(Conv2D(cnn_nodes*multiplier, (3, 3), kernel_regularizer = reg))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        multiplier += 2 #powers of 2 increasing hidden layer CNN size\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(full_nodes))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_nodes))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=learn_rate, decay = 1e-6),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model_name = 'N_game_'+str(cnn_nodes)+'cnnStart_'+str(full_nodes)+'full_'+str(hidden_layers)+'hidden_'+str(len(model.layers))+'TotalLayers.h5'\n",
    "\n",
    "    return model,model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel,kmodel_name = create_CNN(testing_data,cnn_nodes=64,full_nodes=512,\n",
    "                                hidden_layers=3,output_nodes=len(testing_labels[0]),learn_rate=1e-3)\n",
    "model_name = img_path+'\\\\models\\\\'+kmodel_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,model_path,num_ep=5,train_data=True,use_generator=False):\n",
    "    \n",
    "    model_name = model_path.split('\\\\')[-1] # get model name from designated save path\n",
    "    \n",
    "    logdir = '.\\\\log\\\\'+model_name\n",
    "    \n",
    "    checkpoint_dir = img_path+\"\\\\check_points\\\\\" # get checkpoint dir\n",
    "    \n",
    "    #If using image generator to augment data\n",
    "    if use_generator is True:\n",
    "        model_path = model_path.split('.')[0]+'_Generator.'+model_path.split('.')[1]\n",
    "        \n",
    "    # Establish callbacks for model\n",
    "    checkpoint_path = checkpoint_dir+model_name+\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    \n",
    "    cp_callback = ModelCheckpoint(checkpoint_path,monitor='val_acc',save_best_only=True,verbose=0,mode='auto')\n",
    "    early_stop = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=3, verbose=1, \n",
    "                                              mode='auto', baseline=None, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                  patience=2, min_lr=1e-11)\n",
    "    nan_term = TerminateOnNaN()\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir = logdir,histogram_freq=0,write_graph=False,\n",
    "                                             write_grads=True,update_freq='epoch')\n",
    "\n",
    "    callback_list = [cp_callback,early_stop,reduce_lr,nan_term,tensorboard]\n",
    "    \n",
    "    \n",
    "    # check if model already exists. If it does, load weights of best epoch and continue training\n",
    "    epNum = []\n",
    "    epVal_acc = []\n",
    "    if os.path.exists('{}'.format(model_path)):\n",
    "        for cp in os.listdir(checkpoint_dir):\n",
    "            if model_name in cp:\n",
    "                epNum.append(int(cp[-12:-10]))\n",
    "                epVal_acc.append(float(cp[-9:-5]))\n",
    "        if epVal_acc:\n",
    "            best_ep = epNum[np.argmax(epVal_acc)]\n",
    "            model.load_weights(checkpoint_path.format(epoch=best_ep,val_acc=max(epVal_acc)))\n",
    "\n",
    "            num_ep = best_ep+num_ep\n",
    "\n",
    "            print('Weights loaded!')\n",
    "        else: \n",
    "            best_ep = 0\n",
    "    else:\n",
    "        best_ep = 0 # If model not found will train from scratch\n",
    "        if train_data is True:\n",
    "            print('No version of model found, proceeding to train new model from scratch...')\n",
    "        else: \n",
    "            print('No version of model found.')\n",
    "\n",
    "    if train_data is True:\n",
    "        if use_generator is True:\n",
    "            model.fit_generator(train_generator,epochs=num_ep,initial_epoch=best_ep,\n",
    "                                 steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                                 validation_data = validation_generator,\n",
    "                                 validation_steps = validation_generator.n//validation_generator.batch_size,\n",
    "                                 verbose=1,callbacks=callback_list)\n",
    "        else:\n",
    "            model.fit(x=training_dataNorm,y=np.array(training_labels),epochs=num_ep,verbose=1,shuffle=True,\n",
    "                       validation_data = (testing_dataNorm,test_labels), initial_epoch=best_ep,\n",
    "                       callbacks=callback_list)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel_trained=train_model(kmodel,model_name,num_ep=5,use_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_acc = kmodel_trained.evaluate(testing_dataNorm, y=np.array(testing_labels),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_results_plot(model):\n",
    "    history = model.history.history\n",
    "    x = model.history.epoch\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(10,10))\n",
    "    #plt.subplot(1,2,1)\n",
    "    plt.plot(x,history[\"loss\"],'r',label=\"train_loss\")\n",
    "    plt.plot(x,history[\"acc\"],'g',label=\"train_acc\")\n",
    "    plt.plot(x,history[\"val_loss\"],'r--',label=\"val_loss\")\n",
    "    plt.plot(x,history[\"val_acc\"],'g--',label=\"val_acc\")\n",
    "    plt.title(\"Training/Val Loss and Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    #plt.subplot(1,2,2)\n",
    "    #keras.utils.plot_model(kmodel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_results_plot(kmodel_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output shape of specific layers\n",
    "\n",
    "import six\n",
    "def get_activations(img, model, layer, batch_size=128):\n",
    "    \"\"\"\n",
    "    Return the output of the specified layer for input `x`. `layer` is specified by layer index (between 0 and\n",
    "    `nb_layers - 1`) or by name. The number of layers can be determined by counting the results returned by\n",
    "    calling `layer_names`.\n",
    "    :param x: Input for computing the activations.\n",
    "    :type x: `np.ndarray`. Example: x.shape = (80, 80, 3)\n",
    "    :param model: pre-trained Keras model. Including weights.\n",
    "    :type model: keras.engine.sequential.Sequential. Example: model.input_shape = (None, 80, 80, 3)\n",
    "    :param layer: Layer for computing the activations\n",
    "    :type layer: `int` or `str`. Example: layer = 'flatten_2'\n",
    "    :param batch_size: Size of batches.\n",
    "    :type batch_size: `int`\n",
    "    :return: The output of `layer`, where the first dimension is the batch size corresponding to `x`.\n",
    "    :rtype: `np.ndarray`. Example: activations.shape = (1, 2000)\n",
    "    \"\"\"   \n",
    "    layer_names = [layer.name for layer in model.layers]\n",
    "    if isinstance(layer, six.string_types):\n",
    "        if layer not in layer_names:\n",
    "            raise ValueError('Layer name %s is not part of the graph.' % layer)\n",
    "        layer_name = layer\n",
    "    elif isinstance(layer, int):\n",
    "        if layer < 0 or layer >= len(layer_names):\n",
    "            raise ValueError('Layer index %d is outside of range (0 to %d included).'\n",
    "                             % (layer, len(layer_names) - 1))\n",
    "        layer_name = layer_names[layer]\n",
    "    else:\n",
    "        raise TypeError('Layer must be of type `str` or `int`.')\n",
    "\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    layer_input = model.input\n",
    "    output_func = K.function([layer_input, K.learning_phase()], [layer_output])\n",
    "\n",
    "    # Apply preprocessing\n",
    "    if img.shape == K.int_shape(model.input)[1:]:\n",
    "        x_preproc = np.expand_dims(img, 0)\n",
    "    else:\n",
    "        x_preproc = img\n",
    "    assert len(x_preproc.shape) == 4\n",
    "\n",
    "    # Determine shape of expected output and prepare array\n",
    "    output = output_func([x_preproc,1])[0]\n",
    "    output_shape = output_func([x_preproc[0][None, ...]])[0].shape\n",
    "    activations = np.zeros((x_preproc.shape[0],) + output_shape[1:], dtype=np.float32)\n",
    "\n",
    "    # Get activations with batching\n",
    "    for batch_index in range(int(np.ceil(x_preproc.shape[0] / float(batch_size)))):\n",
    "        begin, end = batch_index * batch_size, min((batch_index + 1) * batch_size, x_preproc.shape[0])\n",
    "        activations[begin:end] = output_func([x_preproc[begin:end]])[0]\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
