{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import re\n",
    "import pickle\n",
    "import pyautogui\n",
    "from PIL import ImageGrab, Image\n",
    "from difflib import SequenceMatcher\n",
    "import tensorflow as tf\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "import time\n",
    "import win32gui, win32con, win32com.client\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to include in script for pytesseract to work\n",
    "pytesseract.pytesseract.tesseract_cmd = 'D:\\\\VideoGame_AI\\\\third_party\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Gym Environment for N Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    metadata={'render.modes':['human']}\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        \n",
    "        # bounds for image grab. Note: This is for when the game is fullscreen\n",
    "        left_x_bound = 430\n",
    "        top_y_bound = 170\n",
    "        right_x_bound = 1485\n",
    "        bottom_y_bound = 900\n",
    "        self.whole_screen_bounds =(left_x_bound,top_y_bound,right_x_bound,bottom_y_bound)\n",
    "\n",
    "        # bounds for amount of time left. Necessary for reward\n",
    "        self.time_left_bounds = (490,170,565,190)\n",
    "\n",
    "        # bounds for level completion message\n",
    "        self.lvlComplete_msgBounds = (845,290,1070,310)\n",
    "\n",
    "        # threshold for end level message detection\n",
    "        self.lvlComplete_msgThresh = 0.80\n",
    "\n",
    "        # shape of the observation\n",
    "        self.observation_height = 530\n",
    "        self.observation_width = 370\n",
    "        self.observation_channels = 3\n",
    "        \n",
    "        \n",
    "        # agent can go left,right, space\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # input will be an image. for now we will say the shape is (60,60,3)\n",
    "        self.observation_space = spaces.Box(low=0, high=255,\n",
    "                                           shape=(self.observation_height,\n",
    "                                                  self.observation_width,\n",
    "                                                  self.observation_channels), \n",
    "                                            dtype=np.uint8)\n",
    "        \n",
    "    def reset(self):\n",
    "        # press K to kill agent and reset\n",
    "        pyautogui.press(action_lookup[3])\n",
    "        \n",
    "        # press SPACE to continue\n",
    "        pyautogui.press(action_lookup[2])\n",
    "        \n",
    "        # press Z to start\n",
    "        pyautogui.press(action_lookup[2])\n",
    "        \n",
    "        # capture the screen on restart\n",
    "        observation, lvl_initialTime = self.screen_capture()\n",
    "        \n",
    "        # save so we can use for the reward function\n",
    "        self.lvl_initialTime = lvl_initialTime\n",
    "        \n",
    "        self.prev_stepTime = self.lvl_initialTime\n",
    "        \n",
    "        return observation\n",
    "    \n",
    "    def step(self, action):\n",
    "        action_key = action_lookup[action]\n",
    "        \n",
    "        # key press\n",
    "        pyautogui.press(action_key)\n",
    "        \n",
    "        # capture updated screen\n",
    "        observation, lvl_time = self.screen_capture()\n",
    "        \n",
    "        # determine if we are done. Capture end of level message and see how close\n",
    "        self.text_ratio = self.detect_end_levelMessage()\n",
    "        \n",
    "        done = bool(self.text_ratio >= self.lvlComplete_msgThresh)\n",
    "\n",
    "        # Two rewards here:\n",
    "        # One for completing the level\n",
    "        lvl_completeReward = 1 if done else 0\n",
    "        \n",
    "        # Another for the amount of time it took to complete the level (ratio)\n",
    "        # If the agent has obtained a yellow square, which increases its current level time\n",
    "        # then set the time reward equal to the ratio of current time to intial level time\n",
    "        if lvl_time > self.prev_stepTime:\n",
    "            time_rewardRatio = lvl_time/self.lvl_initialTime\n",
    "        else:\n",
    "            time_rewardRatio = 0\n",
    "        \n",
    "        self.prev_stepTime = lvl_time\n",
    "        \n",
    "        reward = time_rewardRatio+lvl_completeReward\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def screen_capture(self):\n",
    "        \n",
    "        # capture the screen on restart\n",
    "        screen = np.array(ImageGrab.grab(bbox=self.whole_screen_bounds))\n",
    "        \n",
    "        # resize the screen\n",
    "        observation = cv2.resize(screen,(self.observation_height,self.observation_width))\n",
    "        \n",
    "        # get the intial amount of time the agent has to complete the level\n",
    "        time_capture = np.array(ImageGrab.grab(bbox=self.time_left_bounds))\n",
    "        \n",
    "        time_captureGS = cv2.cvtColor(time_capture,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # use pytesseract to extract digits from image\n",
    "        extracted_time = pytesseract.image_to_string(Image.fromarray(time_captureGS),lang='eng',\n",
    "                           config='--psm 8 -c tessedit_char_whitelist=.0123456789',\n",
    "                            output_type='string')\n",
    "        \n",
    "        # convert extracted time to float\n",
    "        try:\n",
    "            lvl_time = round(float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\",extracted_time)[0]),2)\n",
    "        except Exception:\n",
    "            plt.imshow(time_captureGS)\n",
    "            print(extracted_time)\n",
    "            \n",
    "        return observation, lvl_time\n",
    "    \n",
    "    def detect_end_levelMessage(self):\n",
    "        \n",
    "        # determine if the end level message is present\n",
    "        message_capture = np.array(ImageGrab.grab(bbox=self.lvlComplete_msgBounds))\n",
    "        \n",
    "        message_gs = cv2.cvtColor(message_capture,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        extracted_text = pytesseract.image_to_string(Image.fromarray(message_gs),\n",
    "                            config = '--psm 7',\n",
    "                            lang='eng')\n",
    "        \n",
    "        message_text = extracted_text.rstrip()\n",
    "        \n",
    "        # determine how similar the text is to the true message\n",
    "        true_message = 'level complete! press JUMP to continue'\n",
    "        \n",
    "        # get similarity between true text and extracted text\n",
    "        textSimilarity_ratio = round(SequenceMatcher(None,message_text,true_message).ratio(),2)\n",
    "        \n",
    "        return textSimilarity_ratio\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "        \n",
    "# action dictionary. Note: 0x4B is mapped onto the 'K' key\n",
    "action_lookup = {\n",
    "    0 : 'left',\n",
    "    1 : 'right',\n",
    "    2 : 'z',\n",
    "    3 : 'k'\n",
    "}     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if Environment works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env,warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the game\n",
    "os.startfile('D:\\\\Nv2-PC.exe')\n",
    "first_game_start = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "- [ ] Figure out how to send consistent key inputs to game\n",
    "- [ ] Create NN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch focus to the game window so actions register\n",
    "hwnd = win32gui.FindWindow(None,'Adobe Flash Player 11')\n",
    "\n",
    "# do this to avoid errors\n",
    "shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "shell.SendKeys('%')\n",
    "\n",
    "# set focus on window\n",
    "win32gui.SetForegroundWindow(hwnd)\n",
    "\n",
    "# maximize window\n",
    "tup = win32gui.GetWindowPlacement(hwnd)\n",
    "if tup[1] != win32con.SW_SHOWMAXIMIZED:\n",
    "    win32gui.ShowWindow(hwnd, win32con.SW_MAXIMIZE)\n",
    "\n",
    "    \n",
    "if first_game_start:\n",
    "    # click on play game and first level\n",
    "    play_game_xy = (1244,427)\n",
    "\n",
    "    select_lvl_xy = (549,323)\n",
    "\n",
    "    pyautogui.click(x = play_game_xy[0], y = play_game_xy[1])\n",
    "    pyautogui.click(x = select_lvl_xy[0], y = select_lvl_xy[1])\n",
    "\n",
    "    first_game_start = 0\n",
    "\n",
    "time.sleep(3)\n",
    "env = CustomEnv()\n",
    "observation = env.reset()\n",
    "for x in range(0,5):\n",
    "    obs, rew, done, info = env.step(env.action_space.sample())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
