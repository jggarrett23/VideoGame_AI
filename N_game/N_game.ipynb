{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "from numpy import ones, vstack\n",
    "from numpy.linalg import lstsq\n",
    "import pyautogui\n",
    "from statistics import mean\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directkeys import PressKey, LEFT, RIGHT, SPACE, Z, ESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(img, vertices):\n",
    "    \n",
    "    #blank mask:\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked = cv2.bitwise_and(img, mask)\n",
    "    return masked\n",
    "\n",
    "def process_img(image):\n",
    "    original_image = image\n",
    "    # convert to gray\n",
    "    processed_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # edge detection\n",
    "    processed_img =  cv2.Canny(processed_img, threshold1 = 200, threshold2=300)\n",
    "    \n",
    "    processed_img = cv2.GaussianBlur(processed_img,(5,5),0)\n",
    "    \n",
    "    vertices = np.array([[0,850],[0,65],[925,65],[925,850],\n",
    "                         ], np.int32)\n",
    "\n",
    "    processed_img = roi(processed_img, [vertices])\n",
    "\n",
    "    # more info: http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
    "    #                                     rho   theta   thresh  min length, max gap:        \n",
    "    lines = cv2.HoughLinesP(processed_img, 1, np.pi/180, 180,      20,       15)\n",
    "    draw_lines (process_img,lines)\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img,lines):\n",
    "    try:\n",
    "        for line in lines:\n",
    "            coords = line[0]\n",
    "            cv2.line(img,(coords[0],coords[1]),(coords[2],coords[3]), [255,255,255],3)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pyramid of image to help with classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    " \n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "\n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "\n",
    "        # yield the next image in the pyramid\n",
    "        yield image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliding Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "        # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes,labels,overlapThresh):\n",
    "# if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "        \n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    " \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    " \n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        #only delete overlapping boxes that have been classified as the same\n",
    "        found_overlaps = np.where(overlap > overlapThresh)[0]\n",
    "        if found_overlaps.shape > (1,):\n",
    "            for i in found_overlaps:\n",
    "                for j in found_overlaps:\n",
    "                    if i != j and labels[i][0] == labels[j][0]:\n",
    "                        found_overlaps = []\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "        found_overlaps)))\n",
    "\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return pick,boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0102 20:13:29.406698  2196 __init__.py:690] \n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import N_Game_func\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'C:\\\\Users\\\\Jordan\\\\Desktop\\\\N_game_images\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,merged_labels = N_Game_func.original_labels(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0102 20:13:30.702289  2196 module_wrapper.py:137] From C:\\Users\\Jordan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0102 20:13:30.741271  2196 module_wrapper.py:137] From C:\\Users\\Jordan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0102 20:13:31.507528  2196 module_wrapper.py:137] From C:\\Users\\Jordan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0102 20:13:31.567398  2196 deprecation.py:323] From C:\\Users\\Jordan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model(parent_dir+'models\\\\preTrained_VGG_trainLast3_Generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(parent_dir+'check_points\\\\preTrained_VGG_trainLast3_Generator_weights-improvement-36-0.83.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draws rectangle over sliding window and labels window's classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(winW, winH) = (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i,sub_img in enumerate(pyramid(screen)):\n",
    "def classify_screen(screen,model,labels,tolerance=0.8,winSize = (30,30),\n",
    "                   winStep = 32,screenResize = (800,500)):\n",
    "    sub_img=cv2.resize(screen,screenResize)\n",
    "    #start = time.time()\n",
    "\n",
    "    classd_positions = []\n",
    "    classd_labels = []\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "    for (x, y, window) in sliding_window(sub_img, stepSize=winStep, \n",
    "                                         windowSize=winSize):\n",
    "\n",
    "        # if the window does not meet our desired window size, ignore it\n",
    "        if window.shape[0] != winH or window.shape[1] != winW:\n",
    "            continue\n",
    "\n",
    "        test_window = cv2.resize(window,model.input_shape[1:3])\n",
    "        test_img = np.expand_dims(test_window,0)\n",
    "        prediction = model.predict(test_img/255.)\n",
    "\n",
    "        conf = np.max(prediction)\n",
    "\n",
    "        if conf > tolerance:\n",
    "            classd_positions.append([x,y,x+winW,y+winH])\n",
    "\n",
    "            classified_label = labels[np.argmax(prediction)]\n",
    "            classd_labels.append([classified_label,conf])\n",
    "\n",
    "    if not classd_positions:\n",
    "        raise Exception(\"NO PREDICTIONS MADE\")\n",
    "    #filter overlapping boxes\n",
    "    classd_positions = np.array(classd_positions)\n",
    "    boxIdx,no_overlapBoxes = non_max_suppression_fast(classd_positions,\n",
    "                                                      classd_labels,.2)\n",
    "\n",
    "    #filter/sort labels according to boxes idx\n",
    "    array_labels = np.array(classd_labels)\n",
    "    classd_labels = array_labels[boxIdx]\n",
    "\n",
    "    #get confidence values for N character detection\n",
    "    n_conf = [lab[1] for lab in classd_labels if 'N' in lab]\n",
    "    switch_conf = [lab[1] for lab in classd_labels if 'Switch' in lab]\n",
    "    OD_conf = [lab[1] for lab in classd_labels if 'OD' in lab]\n",
    "    dup_idx = []\n",
    "    for idx,lab in enumerate(classd_labels):\n",
    "        if 'N' in lab and max(n_conf) not in lab:\n",
    "            dup_idx = np.append(dup_idx,idx)\n",
    "        elif 'Switch' in lab and max(switch_conf) not in lab:\n",
    "            dup_idx = np.append(dup_idx,idx)\n",
    "        elif 'OD' in lab and max(OD_conf) not in lab:\n",
    "            dup_idx = np.append(dup_idx,idx)\n",
    "\n",
    "    classd_labels = np.delete(classd_labels,dup_idx,0)\n",
    "    no_overlapBoxes = np.delete(no_overlapBoxes,dup_idx,0)\n",
    "\n",
    "    #draw predictions on image\n",
    "    clone=sub_img.copy()\n",
    "    for n,pos in enumerate(no_overlapBoxes):\n",
    "        x1 = pos[0]\n",
    "        y1 = pos[1]\n",
    "        x2 = pos[2]\n",
    "        y2 = pos[3]\n",
    "\n",
    "        label = classd_labels[n][0]\n",
    "        percent = float(classd_labels[n][1])*100\n",
    "\n",
    "        img_text = \"{}:{:2.0f}%\".format(label,percent)\n",
    "\n",
    "        cv2.rectangle(clone,(x1,y1), (x2,y2),(0,255,0),2)\n",
    "        cv2.putText(clone,img_text,(x1,y1),cv2.FONT_HERSHEY_SIMPLEX,0.3,\n",
    "                   (255,255,255), lineType=cv2.LINE_AA)\n",
    "\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start))\n",
    "    #cv2.imshow(\"Window\",clone)\n",
    "    #if cv2.waitKey(0)==ord('c'):\n",
    "        #continue\n",
    "    #elif cv2.waitKey(0)==ord('q'):\n",
    "        #cv2.destroyAllWindows()\n",
    "        #break\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "        #clone = resized.copy()\n",
    "        #cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "        #cv2.putText(clone, classified_label, (x, y+winH), cv2.FONT_HERSHEY_SIMPLEX, 1.0, \n",
    "                        #(255, 255, 255), lineType=cv2.LINE_AA) \n",
    "        #cv2.imshow(\"Window\", clone)\n",
    "        #k=cv2.waitKey(0)\n",
    "        #if k==ord('a'):\n",
    "            #time.sleep(0.025)\n",
    "        #elif k == ord('q'):\n",
    "            #cv2.destroyAllWindows()\n",
    "            #break\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "    return clone,classd_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    last_time = time.time()\n",
    "    while True:\n",
    "        #PressKey(RIGHT)\n",
    "        screen = np.array(ImageGrab.grab(bbox=(0,100,950,830)))\n",
    "        \n",
    "        try:\n",
    "            clone,detected_labs = classify_screen(screen,model,\n",
    "                                                  merged_labels,\n",
    "                                                 tolerance = .1)\n",
    "            cv2.imshow('window2',clone)\n",
    "        except:\n",
    "            clone = screen\n",
    "\n",
    "        print('Frame took {} seconds'.format(time.time()-last_time))\n",
    "        last_time = time.time()\n",
    "        #new_screen = process_img(screen)\n",
    "        #cv2.imshow('window', new_screen)\n",
    "        \n",
    "        #cv2.imshow('window',cv2.cvtColor(screen, cv2.COLOR_BGR2RGB))\n",
    "        #press q to close screen\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = np.array(ImageGrab.grab(bbox=(0,60,930,800)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ed1d29a5f8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(cv2.cvtColor(screen, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = imutils.resize(screen,width=int(633/1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:54: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "C:\\Users\\Jordan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:55: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "clone,detected_labs = classify_screen(screen,model,\n",
    "                                                  merged_labels,\n",
    "                                                 tolerance = .5)\n",
    "cv2.imshow('Window',clone)\n",
    "if cv2.waitKey(0) == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
